# -*- coding: utf-8 -*-
"""Closed-Loop ADAS for a Wheeled Robot (Real Time).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CgAwjAQQ0hSZSKFzXyOaI_dBBMsWuExV

# Integrated Lane Detection, MPC Steering, and Collision Warning
"""

!pip install ultralytics

"""### Whole code in one snippet"""

import cv2
import numpy as np
import torch
from ultralytics import YOLO
import time
import cvxpy as cp

# Load YOLOv8 model
model = YOLO('yolov8n.pt')

# Collision warning parameters
COLLISION_WARNING_DISTANCE = 2.0  # Warning threshold in meters
prev_positions = {}  # Store previous frame positions of objects
prev_time = time.time()

# Depth estimation parameters
FOCAL_LENGTH = 700  # Adjust based on camera calibration
KNOWN_WIDTH = 1.8  # Approximate width of detected vehicles in meters

# Lane detection and MPC parameters
def region_of_interest(frame, vertices):
    mask = np.zeros_like(frame)
    cv2.fillPoly(mask, vertices, 255)
    return cv2.bitwise_and(frame, mask)

def draw_lines(frame, lines, color=(0, 255, 0)):
    if lines is None:
        return
    for line in lines:
        x1, y1, x2, y2 = line[0]
        cv2.line(frame, (x1, y1), (x2, y2), color, 10)

def calculate_centerline(lines, frame_shape):
    left_line_x, left_line_y, right_line_x, right_line_y = [], [], [], []

    for line in lines:
        x1, y1, x2, y2 = line[0]
        slope = (y2 - y1) / (x2 - x1 + 0.01)
        if slope < -0.3:
            left_line_x.extend([x1, x2])
            left_line_y.extend([y1, y2])
        elif slope > 0.3:
            right_line_x.extend([x1, x2])
            right_line_y.extend([y1, y2])

    if left_line_x and right_line_x:
        left_poly = np.polyfit(left_line_y, left_line_x, 1)
        right_poly = np.polyfit(right_line_y, right_line_x, 1)
        left_bottom, right_bottom = np.polyval(left_poly, frame_shape[0]), np.polyval(right_poly, frame_shape[0])
        return int((left_bottom + right_bottom) / 2)
    return None

def mpc_control(deviation, N=10):
    delta = cp.Variable(N)
    cost = sum(cp.square(deviation + t * delta[t]) + 0.1 * cp.square(delta[t]) for t in range(N))
    constraints = [cp.abs(delta[t]) <= 0.5 for t in range(N)]
    problem = cp.Problem(cp.Minimize(cost), constraints)
    problem.solve()
    return delta.value[0] if delta.value is not None else 0

cap = cv2.VideoCapture(0)
if not cap.isOpened():
    print("Error: Could not open video.")
    exit()

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(gray, (5, 5), 0)
    edges = cv2.Canny(blur, 50, 150)

    height, width = frame.shape[:2]
    roi_vertices = np.array([[(0, height), (width, height), (width // 2, height // 2)]], dtype=np.int32)
    cropped_edges = region_of_interest(edges, roi_vertices)

    lines = cv2.HoughLinesP(cropped_edges, rho=2, theta=np.pi / 180, threshold=100, minLineLength=50, maxLineGap=200)

    if lines is not None:
        draw_lines(frame, lines)
        road_center_x = calculate_centerline(lines, frame.shape)

        if road_center_x is not None:
            cv2.line(frame, (road_center_x, height), (road_center_x, height // 2), (255, 0, 0), 5)
            camera_center_x = width // 2
            cv2.line(frame, (camera_center_x, height), (camera_center_x, height // 2), (0, 0, 255), 5)

            deviation = camera_center_x - road_center_x
            steering_adjustment = mpc_control(deviation)

            cv2.putText(frame, f'Steering Adjustment: {steering_adjustment:.2f}', (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
            steer_end_x = int(camera_center_x - steering_adjustment * 100)
            cv2.line(frame, (camera_center_x, height), (steer_end_x, height - 100), (0, 255, 255), 3)

    results = model(frame)
    curr_time = time.time()
    elapsed_time = curr_time - prev_time
    prev_time = curr_time

    for result in results[0].boxes:
        x1, y1, x2, y2 = map(int, result.xyxy[0])
        object_id = result.cls.item()
        label = model.names[int(object_id)]
        center = ((x1 + x2) // 2, (y1 + y2) // 2)
        box_width_px = x2 - x1

        distance = (KNOWN_WIDTH * FOCAL_LENGTH) / box_width_px if box_width_px > 0 else float('inf')

        if object_id in prev_positions:
            prev_center = prev_positions[object_id]
            pixel_distance = np.linalg.norm(np.array(center) - np.array(prev_center))
            scale = distance / FOCAL_LENGTH
            real_distance = pixel_distance * scale
            estimated_speed = real_distance / elapsed_time if elapsed_time > 0 else 0
        else:
            estimated_speed = 0

        prev_positions[object_id] = center

        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(frame, f"{label} - Dist: {distance:.2f}m, Speed: {estimated_speed:.2f} m/s",
                    (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)

        if distance < COLLISION_WARNING_DISTANCE:
            cv2.putText(frame, "Collision Warning!", (x1, y1 - 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)

    cv2.putText(frame, "Road Centerline (Blue), Camera Centerline (Red), Steering Direction (Yellow)",
                (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
    cv2.imshow("Integrated Lane Detection, MPC Steering, and Collision Warning", frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

"""### Whole code in different snippets for better understanding"""

# Imports
import cv2
import numpy as np
import torch
from ultralytics import YOLO
import time
import cvxpy as cp

# Load YOLOv8 Model
model = YOLO('yolov8n.pt')

# Collision Warning Parameters
COLLISION_WARNING_DISTANCE = 2.0  # in meters
prev_positions = {}              # Store previous frame object positions
prev_time = time.time()          # Time tracking for speed estimation

# Depth Estimation Parameters
FOCAL_LENGTH = 700               # Camera-specific (in pixels)
KNOWN_WIDTH = 1.8                # Approx. width of a car (in meters)

"""## Lane Detection and MPC Steering"""

# Masking region of interest for lane detection
def region_of_interest(frame, vertices):
    mask = np.zeros_like(frame)
    cv2.fillPoly(mask, vertices, 255)
    return cv2.bitwise_and(frame, mask)

# Draw detected lane lines on frame
def draw_lines(frame, lines, color=(0, 255, 0)):
    if lines is None:
        return
    for line in lines:
        x1, y1, x2, y2 = line[0]
        cv2.line(frame, (x1, y1), (x2, y2), color, 10)

# Calculate centerline between left and right lane
def calculate_centerline(lines, frame_shape):
    left_line_x, left_line_y, right_line_x, right_line_y = [], [], [], []

    for line in lines:
        x1, y1, x2, y2 = line[0]
        slope = (y2 - y1) / (x2 - x1 + 0.01)  # Prevent division by zero
        if slope < -0.3:  # Left lane
            left_line_x.extend([x1, x2])
            left_line_y.extend([y1, y2])
        elif slope > 0.3:  # Right lane
            right_line_x.extend([x1, x2])
            right_line_y.extend([y1, y2])

    if left_line_x and right_line_x:
        left_poly = np.polyfit(left_line_y, left_line_x, 1)
        right_poly = np.polyfit(right_line_y, right_line_x, 1)
        left_bottom = np.polyval(left_poly, frame_shape[0])
        right_bottom = np.polyval(right_poly, frame_shape[0])
        return int((left_bottom + right_bottom) / 2)
    return None

# Model Predictive Control for steering
def mpc_control(deviation, N=10):
    delta = cp.Variable(N)
    cost = sum(cp.square(deviation + t * delta[t]) + 0.1 * cp.square(delta[t]) for t in range(N))
    constraints = [cp.abs(delta[t]) <= 0.5 for t in range(N)]
    problem = cp.Problem(cp.Minimize(cost), constraints)
    problem.solve()
    return delta.value[0] if delta.value is not None else 0

# ðŸ“· Video Capture Setup
cap = cv2.VideoCapture(0)  # Use 0 for default webcam
if not cap.isOpened():
    print("Error: Could not open video.")
    exit()

"""No camera attached"""

# Main Processing Loop

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # Lane Detection
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(gray, (5, 5), 0)
    edges = cv2.Canny(blur, 50, 150)

    height, width = frame.shape[:2]
    roi_vertices = np.array([[(0, height), (width, height), (width // 2, height // 2)]], dtype=np.int32)
    cropped_edges = region_of_interest(edges, roi_vertices)

    lines = cv2.HoughLinesP(cropped_edges, rho=2, theta=np.pi / 180,
                            threshold=100, minLineLength=50, maxLineGap=200)

    if lines is not None:
        draw_lines(frame, lines)
        road_center_x = calculate_centerline(lines, frame.shape)

        if road_center_x is not None:
            # Draw centerlines
            cv2.line(frame, (road_center_x, height), (road_center_x, height // 2), (255, 0, 0), 5)  # Blue
            camera_center_x = width // 2
            cv2.line(frame, (camera_center_x, height), (camera_center_x, height // 2), (0, 0, 255), 5)  # Red

            # MPC steering calculation
            deviation = camera_center_x - road_center_x
            steering_adjustment = mpc_control(deviation)

            # Display steering adjustment
            cv2.putText(frame, f'Steering Adjustment: {steering_adjustment:.2f}', (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)

            # Draw steering direction (yellow line)
            steer_end_x = int(camera_center_x - steering_adjustment * 100)
            cv2.line(frame, (camera_center_x, height), (steer_end_x, height - 100), (0, 255, 255), 3)


    # Object Detection with YOLO
    results = model(frame)
    curr_time = time.time()
    elapsed_time = curr_time - prev_time
    prev_time = curr_time

    for result in results[0].boxes:
        x1, y1, x2, y2 = map(int, result.xyxy[0])
        object_id = result.cls.item()
        label = model.names[int(object_id)]
        center = ((x1 + x2) // 2, (y1 + y2) // 2)
        box_width_px = x2 - x1

        # Estimate distance using width in pixels
        distance = (KNOWN_WIDTH * FOCAL_LENGTH) / box_width_px if box_width_px > 0 else float('inf')

        # Estimate object speed if seen in previous frame
        if object_id in prev_positions:
            prev_center = prev_positions[object_id]
            pixel_distance = np.linalg.norm(np.array(center) - np.array(prev_center))
            scale = distance / FOCAL_LENGTH
            real_distance = pixel_distance * scale
            estimated_speed = real_distance / elapsed_time if elapsed_time > 0 else 0
        else:
            estimated_speed = 0

        prev_positions[object_id] = center

        # Draw bounding box and info
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(frame, f"{label} - Dist: {distance:.2f}m, Speed: {estimated_speed:.2f} m/s",
                    (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)

        # Collision warning
        if distance < COLLISION_WARNING_DISTANCE:
            cv2.putText(frame, "Collision Warning!", (x1, y1 - 30), cv2.FONT_HERSHEY_SIMPLEX,
                        1, (0, 0, 255), 2)
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)

    # Display Frame with Overlays
    cv2.putText(frame, "Road Centerline (Blue), Camera Centerline (Red), Steering Direction (Yellow)",
                (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
    cv2.imshow("Integrated Lane Detection, MPC Steering, and Collision Warning", frame)

    # Exit Condition
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Cleanup
cap.release()
cv2.destroyAllWindows()

""" if the camera isn't available, cap won't exist, causing NameError."""

